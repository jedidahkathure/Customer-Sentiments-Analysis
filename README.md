<!-- ğŸ–¼ï¸ Placeholder for Top Banner -->
<p align="center">
  <img src="EDAviz/banner.png" alt="Customer Sentiment Analysis Banner" width="90%">
</p>

<h1 align="center"> Analysis for Safaricom & Airtel Apps (Kenya)</h1>
<p align="center">
  <strong>Turning real customer feedback into actionable business intelligence through NLP & Machine Learning</strong>
</p>

---

##  **Authors: Jedidah Kathure | Winnie Amoit | Anthony Njoroge | Anne Mumbe | Navros Kamau | Rachel Odhiambo**

---

##  **Executive Summary**

This project leverages **Natural Language Processing (NLP)** and **Machine Learning (ML)** to analyze thousands of reviews from the **Google Play Store** and **Apple App Store** for Kenyaâ€™s leading telecom apps: **Safaricom (M-PESA, MySafaricom)** and **Airtel (Airtel Money, MyAirtel)**.  

We aimed to understand how customers *feel* about these apps â€” identifying pain points, satisfaction drivers, and opportunities for improvement.  

The end result?  
An intelligent system capable of classifying reviews as **Positive** or **Negative** in real time, helping telcos **track sentiment, detect complaints early, and improve customer experience.**

> â€œEvery review tells a story â€” we turned those stories into business insights.â€ ğŸ’¬

---

## **Introduction**

In Kenyaâ€™s competitive telecom space, where digital financial apps handle millions of transactions daily, *customer experience defines brand loyalty.*  
Safaricom and Airtel users frequently share feedback online â€” yet, most of these insights remain **unstructured and unread.**

Our solution bridges that gap.  
We built a robust sentiment analysis pipeline capable of analyzing thousands of app reviews, visualizing trends, and predicting customer mood using cutting-edge NLP models.

---

##  **Business Understanding**

| Focus Area | Description |
|-------------|-------------|
| **Industry Context** | Telecom competition in Kenya is fierce; retaining satisfied users is more profitable than acquiring new ones. |
| **Pain Point** | App users face performance issues, failed logins, delayed SMS/OTP, and transaction errors. |
| **Opportunity** | Sentiment analysis provides early warnings and quantifiable feedback loops for product and customer-care teams. |

---

##  **Stakeholders & Business Value**

### ğŸ”¹ **Stakeholders**
- **Product Teams** â€“ monitor new feature impact and bug frequency  
- **Customer Experience (CX) Units** â€“ detect and address dissatisfaction early  
- **Marketing Managers** â€“ gauge brand reputation across digital platforms  
- **Executives** â€“ use insights for strategic decisions  
- **Data Science Teams** â€“ maintain and refine the predictive models  

###  **Business Value**
| Value | Description |
|--------|--------------|
| **Customer Insights** | Quantify satisfaction vs frustration to guide product decisions. |
| **Faster Response** | Detect negative reviews in real time and act before escalation. |
| **Retention & Loyalty** | Prevent churn through early issue resolution. |
| **Data-Driven Strategy** | Empower teams with factual evidence for updates, pricing, and UX. |

---

##  **Goals & Objectives**

1. Collect and preprocess app review data from both platforms.  
2. Perform Exploratory Data Analysis (EDA) to visualize user sentiment.  
3. Build and compare **binary** (positive vs negative) and **multiclass** (positive, neutral, negative) models.  
4. Evaluate performance using precision, recall, F1-score, and ROC-AUC.  
5. Deploy the best model for real-time sentiment prediction via **FastAPI**.  
6. Provide actionable insights and recommendations to telecom stakeholders.  

---

## ğŸ“Š **About the Dataset**

| Attribute | Description |
|------------|--------------|
| **Source** | Google Play Store & Apple App Store |
| **Apps Covered** | Safaricom: M-PESA, MySafaricom  â€¢  Airtel: Airtel Money, MyAirtel |
| **Size** | ~5,000 reviews |
| **Columns** | `date`, `app_name`, `platform`, `rating`, `review`, `sentiment` |
| **Engineered Features** | `clean_text`, `review_length`, `word_count`|

**Languages:** English, Swahili, and Sheng  
**Date Range:** 2023-2025  

---

##  **Data Preparation Steps**

1. **Data Collection** â€“ using App Store and Play Store scraping scripts.  
2. **Text Cleaning** â€“ removal of punctuation, emojis, URLs, and noise.  
3. **Tokenization & Lemmatization** â€“ text normalized for NLP.  
4. **Feature Engineering** â€“ polarity, subjectivity, and length metrics added.  
5. **Class Balancing** â€“ applied SMOTE for minority (negative) class.  
6. **Split Data** â€“ 80% train / 20% test.  

---

##  **Dataset Limitations**

- More data from Google Play than App Store â†’ mild platform bias.  
- Multilingual reviews (Swahili/English mix) â†’ occasional misclassification.  
- Very short reviews like â€œGoodâ€ or â€œBadâ€ â†’ limited context.  
- No demographic or regional attributes.  

Despite these constraints, preprocessing ensured **clean, balanced, and high-quality text data.**

---

## ğŸ› ï¸ **Tools & Tech Stack**

| Category | Tools |
|-----------|--------|
| **Programming** | Python 3.12 |
| **Libraries** | Pandas, NumPy, Scikit-learn, NLTK, SpaCy, WordCloud, Matplotlib, Seaborn |
| **Modeling** | Logistic Regression, SVM, Naive Bayes, Decision Tree, Random Forest, XGBoost, BERT |
| **Deployment** | FastAPI, Render |
| **Version Control** | Git & GitHub |
| **Documentation** | Markdown, Jupyter Notebook, PowerPoint |

---

##  **Story Behind the Project**

Originally, the team intended to scrape **Twitter data** for public telecom sentiment.  
However, due to **Twitter API restrictions**, we pivoted to analyzing **App Store reviews**, which offered:  
- App-specific, structured, and richer feedback  
- Continuous review availability  
- Real-world relevance to product teams  

This pivot not only improved data quality but also aligned perfectly with **business use cases.**

---

##  **Analysis & Methodology**

| Phase | Key Action |
|--------|-------------|
| **Data Cleaning** | Removed noise and standardized text. |
| **Exploratory Data Analysis** | Visualized sentiment trends, word frequencies, and app ratings. |
| **Feature Engineering** | Created custom text-based features. |
| **Model Building** | Compared multiple ML algorithms for binary & multiclass problems. |
| **Evaluation** | Used metrics & plots to assess predictive power. |
| **Deployment** | Exposed Logistic Regression (SMOTE) model via FastAPI API. |

---

## ğŸ“Š **Exploratory Data Analysis**

###  Sentiment Overview
![Sentiment Distribution](EDAviz/02_sentiment_distribution_dashboard.png)
*Sentiment distribution across all app reviews.*

###  Word Clouds
![Ratings Dashboard](Output/wordclouds_positive_negative_combined.png)

**Positive keywords:** â€œeasyâ€, â€œfastâ€, â€œreliableâ€  
**Negative keywords:** â€œfailedâ€, â€œslowâ€, â€œOTPâ€, â€œerrorâ€

### â­ Ratings Dashboard
![Ratings Dashboard](EDAviz/01_ratings_dashboard.png)
*Positive ratings dominate, but spikes in low ratings reveal key usability issues.*

---

##  **Modeling Approach**

### ğŸ”¹ Binary Classification
Classified reviews into **Positive (1)** and **Negative (0)** for quick complaint detection.  

### ğŸ”¹ Multiclass Classification
Extended classification into **Positive**, **Neutral**, and **Negative** â€” providing a full picture of customer sentiment.  

### ğŸ”¹ Algorithms Compared
- Logistic Regression (baseline & with SMOTE)  
- Support Vector Machine (SVM)  
- Naive Bayes  
- Decision Tree  
- Random Forest  
- XGBoost  
- DistilBERT Transformer  

---

## âš™ï¸ **Model Evaluation**

###  Binary Model Metrics
![Binary Metrics](Output/binary_metrics_grid_blues.png)

| Model | Strength |
|--------|-----------|
| **XGBoost** | Strongest overall performance |
| **SVM / Decision Tree** | Better for complaint detection |
| **Naive Bayes** | Fastest training time |
| **Logistic Regression (SMOTE)** | Balanced, interpretable, and chosen for deployment âœ… |

---

### ğŸ“‰ Confusion Matrices
![Confusion Matrices](Output/CM_grid_all_models_binary_blues.png)
*Dark squares = correct predictions. All models classify positives well, negatives remain challenging.*

---

###  SMOTE vs BERT
![SMOTE vs BERT](Output/binary_metrics_grid_SMOTE_vs_BERT.png)

**DistilBERT** achieved >92% accuracy â€” strongest overall.  
However, **Logistic Regression (SMOTE)** was selected for production:  
lightweight, explainable, and ideal for real-time sentiment tracking.

---

##  **ROC Curves â€” Binary Classification (Positive vs Negative)**

![ROC Curves - Binary](Output/ROC_all_models_binary_blues.png)

The **Receiver Operating Characteristic (ROC) curve** visualizes how well each model distinguishes between **positive** and **negative** sentiments.

###  **Interpretation**
- Each line represents a modelâ€™s trade-off between **True Positive Rate (Recall)** and **False Positive Rate**.
- The **closer the curve hugs the top-left corner**, the stronger the modelâ€™s ability to correctly identify sentiment.
- The **Area Under the Curve (AUC)** quantifies this â€” higher AUC means better discrimination between positive and negative reviews.

###  Multiclass Classification
<p align="center">
  <img src="Output/multiclass_model_comparison.png" width="90%">
</p>

###  Multiclass Performance Heatmaps
<p align="center">
  <img src="Output/multiclass_performance_heatmap.png" width="45%">
  <img src="Output/final_model_heatmap.png" width="45%">
</p>

*All models achieved >85% accuracy. DistilBERT excelled at capturing neutral nuance.*

---

##  **Evaluation Metrics Explained**

| Metric | Meaning | Why It Matters |
|---------|----------|----------------|
| **Precision** | % of correct positive predictions | Prevents false praise of negative reviews |
| **Recall** | % of actual positives caught | Ensures complaints arenâ€™t missed |
| **F1-Score** | Balance of precision & recall | Evaluates real-world reliability |
| **ROC-AUC** | Measures discrimination power | Higher = better model differentiation |

---

##  **Model Selection Summary**

| Model | Type | Accuracy | Comment |
|--------|------|-----------|----------|
| Logistic Regression (SMOTE) | ML | 88% | Lightweight, interpretable âœ… |
| XGBoost | ML | 89% | Excellent overall but heavier |
| DistilBERT | Transformer | 92% | Best accuracy, slower inference |
| Naive Bayes | ML | 82% | Fast but less accurate |

---

##  **Deployment**

**Framework:** FastAPI  
**Hosting:** Render  
**Model:** Logistic Regression with SMOTE  

### ğŸŒ Live URL
- *Base URL:* [https://customer-sentiments-analysis.onrender.com](https://customer-sentiments-analysis.onrender.com)  
- *Docs (Swagger UI):* [https://customer-sentiments-analysis.onrender.com/docs](https://customer-sentiments-analysis.onrender.com/docs)

**Features:**
- Real-time text sentiment prediction  
- REST API endpoints for integration  
- Interactive Swagger UI documentation  
- Scalable and lightweight  

---

##  **Key Insights**

| Category | Takeaway |
|-----------|-----------|
| **Data** | Majority reviews are positive â€” strong brand equity |
| **Negative Trends** | Complaints about speed, failed logins, network outages |
| **Neutral Feedback** | Represents â€œalmost happyâ€ users â€” easy to convert |
| **Model Performance** | All >85% accuracy; Logistic Regression (SMOTE) ideal for deployment |
| **Business Impact** | Enables proactive issue detection and improved customer experience |

---

##  **Business Impact & Next Steps**

###  **Business Impact**
- Early detection of customer dissatisfaction  
- Support for CX and marketing decisions  
- Measurable reduction in response time to issues  
- Data-driven prioritization for app updates  

###  **Next Steps**
- Add multilingual (Swahili/Sheng) transformer models  
- Automate live dashboards using Streamlit/Power BI  
- Implement continuous model retraining  
- Integrate with CRM systems for automated alerts  

---

##  **Repository Structure**

Customer-Sentiments-Analysis/
â”‚
â”œâ”€â”€ Data/ # Raw & cleaned datasets
â”œâ”€â”€ EDAviz/ # EDA dashboards
â”œâ”€â”€ Output/ # Visuals & model outputs
â”‚ â”œâ”€â”€ CM_grid_all_models_binary_blues.png
â”‚ â”œâ”€â”€ binary_metrics_grid_blues.png
â”‚ â”œâ”€â”€ multiclass_model_comparison.png
â”‚ â”œâ”€â”€ final_model_heatmap.png
â”‚ â””â”€â”€ binary_metrics_grid_SMOTE_vs_BERT.png
â”‚
â”œâ”€â”€ safaricom_airtel_analysis.ipynb # Main analysis notebook
â”œâ”€â”€ presentation.pdf # Stakeholder presentation
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ README.md # Project Documentation


---
```bash
## ğŸ’» **How to Clone & Run Locally**


# 1ï¸âƒ£ Clone the repository
git clone https://github.com/jedidahkathure/Customer-Sentiments-Analysis.git

# 2ï¸âƒ£ Navigate into the project
cd Customer-Sentiments-Analysis

# 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 4ï¸âƒ£ Launch the Jupyter Notebook
jupyter notebook safaricom_airtel_analysis.ipynb

```

##  **Lessons Learned**

-  **Clean & Balanced Data Matters:** Ensuring text is properly preprocessed and balanced greatly improves NLP model accuracy.  
-  **Model Explainability is Crucial:** Logistic Regression proved valuable not just for performance, but for its interpretability in business settings.  
-  **Adaptability in Real-World Data:** Pivoting from Twitter to App Store reviews highlighted the importance of flexibility in data sourcing.  
-  **Collaboration & Version Control:** Coordinating across multiple contributors with Git and GitHub enhanced teamwork and reproducibility.  

---

##  **Acknowledgments**

Special thanks to:  
-  **Moringa School** â€“ for mentorship and guidance  
-  **Technical Mentors** â€“ Shout out to our TM Samuel G. Mwangi (SamG)!
-  **Safaricom & Airtel App Users** â€“ whose voices made this analysis meaningful.  
-  **Open-Source Community** â€“ for providing the powerful NLP tools and libraries we used.  

---

## â“ **Questions & Contributions**

ğŸ’¬ Have feedback or suggestions?  
Open an issue, fork this repository, or connect with us on LinkedIn to collaborate!  

---

##  **Support**

If this project inspired or helped you:  
â­ **Star this repository** to show your support.  
â¤ï¸ **Share it** with your peers and community.  
ğŸ§  **Follow us** for more impactful, data-driven projects.  

---
